{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5f10c28",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74d57851",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T17:07:15.340836Z",
     "start_time": "2024-06-15T17:07:14.174864Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import sampler\n",
    "from time import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccf9cf5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T17:07:15.343940Z",
     "start_time": "2024-06-15T17:07:15.342154Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbc2b297",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T17:07:19.756300Z",
     "start_time": "2024-06-15T17:07:15.344724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/liliyaivannikova/Documents/project/git/RecSys_Films/recsyc_part1\n",
      "\n",
      "movies: (86537, 3)\n",
      "rating: (33832162, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "us = os.getcwd()\n",
    "print(us)\n",
    "\n",
    "if 'liliyaivannikova' in us:\n",
    "    PATH = r'/Users/liliyaivannikova/Documents/project/ml-latest/'\n",
    "    movies = pd.read_csv(PATH + r'movies.csv')\n",
    "    rating = pd.read_csv(PATH + r'ratings.csv')\n",
    "elif 'Владислав' in us:\n",
    "    movies = pd.read_csv(r'dataset/movies.csv')\n",
    "    rating = pd.read_csv(r'dataset/ratings.csv')\n",
    "    \n",
    "print(f'''\n",
    "movies: {movies.shape}\n",
    "rating: {rating.shape}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9129d676",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T17:07:20.499484Z",
     "start_time": "2024-06-15T17:07:19.757659Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pf/9t70d84n0wbgzdftsf9jkvtw0000gn/T/ipykernel_6504/1871982909.py:15: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  movies['GENRES'] = movies['GENRES'].str.replace('|', ',')\n"
     ]
    }
   ],
   "source": [
    "movies.columns = [col.upper() for col in movies.columns]\n",
    "movies['REALEASE'] = movies['TITLE'].str.extract(\"\\((\\d{4})\\)\", expand=True)\n",
    "movies['REALEASE'] = pd.to_datetime(movies['REALEASE'], format='%Y')\n",
    "movies['REALEASE'] = movies['REALEASE'].dt.year\n",
    "movies['TITLE'] = movies['TITLE'].str[:-7]\n",
    "\n",
    "# dummy-кодирование жанров\n",
    "dfx = movies['GENRES'].str.get_dummies(sep='|')\n",
    "for col in dfx.columns:\n",
    "    dfx[col] = dfx[col].astype('int8')\n",
    "    \n",
    "movies = pd.concat([movies, dfx], axis=1) #.drop(columns=['GENRES'])\n",
    "movies['TITLE'] = movies['TITLE'].astype('category')\n",
    "movies['REALEASE'] = movies['REALEASE'].astype('float16')\n",
    "movies['GENRES'] = movies['GENRES'].str.replace('|', ',')\n",
    "\n",
    "rating.columns = [col.upper() for col in rating.columns]\n",
    "rating['TIMESTAMP'] = pd.to_datetime(rating['TIMESTAMP'], unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5e78a9",
   "metadata": {},
   "source": [
    "# Фильтрация строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14787f95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T17:07:20.765857Z",
     "start_time": "2024-06-15T17:07:20.500324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считаем кол-во оценок в рамках userid\n",
    "rating_stat = rating.groupby('USERID')['MOVIEID'].count().reset_index()\n",
    "rating_stat['MOVIEID'].quantile(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5387f24d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T17:07:22.388398Z",
     "start_time": "2024-06-15T17:07:20.766728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USERID</th>\n",
       "      <th>MOVIEID</th>\n",
       "      <th>RATING</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>FLAG_05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2008-11-03 17:52:19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2008-11-05 06:04:46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2008-11-03 17:31:43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2008-11-03 18:00:04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>356</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2008-11-03 17:58:39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   USERID  MOVIEID  RATING           TIMESTAMP  FLAG_05\n",
       "0       1        1     4.0 2008-11-03 17:52:19        1\n",
       "1       1      110     4.0 2008-11-05 06:04:46        1\n",
       "2       1      158     4.0 2008-11-03 17:31:43        1\n",
       "3       1      260     4.5 2008-11-03 18:00:04        1\n",
       "4       1      356     5.0 2008-11-03 17:58:39        1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rating_stat['FLAG_05'] = np.where(rating_stat['MOVIEID'] > rating_stat['MOVIEID'].quantile(0.05), 1, 0)\n",
    "'''при текущих симуляцих мы отфильтровали наш набор данных, оставив для построения только userid, которые\n",
    "оценили больше 20 фильмов\n",
    "'''\n",
    "rating_stat['FLAG_05'] = np.where(rating_stat['MOVIEID'] >= rating_stat['MOVIEID'].quantile(0.4), 1, 0)\n",
    "rating = rating.merge(rating_stat[['USERID', 'FLAG_05']], how = 'left', on = 'USERID')\n",
    "rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e47eb771",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T17:07:24.397618Z",
     "start_time": "2024-06-15T17:07:22.389247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32346391, 5)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "По результатам EDA\n",
    "'''\n",
    "# удаляем пропуски\n",
    "rating = rating[~((rating.TIMESTAMP.isna())|(rating.USERID.isna())|(rating.RATING.isna()))]\n",
    "# удаляем странного юзера \n",
    "rating.query('USERID != 189614', inplace = True)\n",
    "# удалим юзеров, у которых оценок меньше 3 (по 5 квантилю)\n",
    "rating.query('FLAG_05 == 1', inplace = True)\n",
    "print(rating.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ddc7ad",
   "metadata": {},
   "source": [
    "# train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "358a1b04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T17:07:24.401100Z",
     "start_time": "2024-06-15T17:07:24.398428Z"
    }
   },
   "outputs": [],
   "source": [
    "rating.rename({'USERID':'user_id',\n",
    "            'MOVIEID':'item_id',\n",
    "            'RATING':'weight',\n",
    "            'TIMESTAMP':'datetime'}, axis=1, inplace=True)\n",
    "\n",
    "movies.rename({'MOVIEID':'item_id'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "7503d71b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T19:43:03.613241Z",
     "start_time": "2024-06-16T19:43:03.578605Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class CriteoDataset(Dataset):\n",
    "     \n",
    "    def __init__(self, data, train=True):\n",
    "        \n",
    "        self.train = train\n",
    "\n",
    "        if not self._check_exists:\n",
    "            raise RuntimeError('Dataset not found.')\n",
    "\n",
    "        if self.train:\n",
    "            self.train_data = data.iloc[:, :-1].values\n",
    "            self.target = data.iloc[:, -1].values\n",
    "        else:\n",
    "            self.test_data = data.iloc[:, :-1].values\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.train:\n",
    "            dataI, targetI = self.train_data[idx, :], self.target[idx]\n",
    "            Xi = torch.from_numpy(dataI.astype(np.int32)).unsqueeze(-1)\n",
    "            Xv = torch.from_numpy(np.ones_like(dataI))\n",
    "            return Xi, Xv, targetI\n",
    "        else:\n",
    "            dataI = self.test_data.iloc[idx, :]\n",
    "            Xi = torch.from_numpy(dataI.astype(np.int32)).unsqueeze(-1)\n",
    "            Xv = torch.from_numpy(np.ones_like(dataI))\n",
    "            return Xi, Xv\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)\n",
    "\n",
    "    def _check_exists(self):\n",
    "        return os.path.exists(self.root)\n",
    "    \n",
    "    \n",
    "class DeepFM(nn.Module):\n",
    "\n",
    "    def __init__(self, feature_sizes, embedding_size=4,\n",
    "                 hidden_dims=[32, 32], num_classes=1, dropout=[0.5, 0.5], \n",
    "                 use_cuda=True, verbose=False):\n",
    "        \"\"\"\n",
    "        Initialize a new network\n",
    "\n",
    "        Inputs: \n",
    "        - feature_size: A list of integer giving the size of features for each field.\n",
    "        - embedding_size: An integer giving size of feature embedding.\n",
    "        - hidden_dims: A list of integer giving the size of each hidden layer.\n",
    "        - num_classes: An integer giving the number of classes to predict. For example,\n",
    "                    someone may rate 1,2,3,4 or 5 stars to a film.\n",
    "        - batch_size: An integer giving size of instances used in each interation.\n",
    "        - use_cuda: Bool, Using cuda or not\n",
    "        - verbose: Bool\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.field_size = len(feature_sizes)\n",
    "        self.feature_sizes = feature_sizes\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.num_classes = num_classes\n",
    "        self.dtype = torch.long\n",
    "        self.bias = torch.nn.Parameter(torch.randn(1))\n",
    "        self.num_correct = 0\n",
    "        self.num_samples = 0\n",
    "        \"\"\"\n",
    "            check if use cuda\n",
    "        \"\"\"\n",
    "        if use_cuda and torch.cuda.is_available():\n",
    "            self.device = torch.device('cuda')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "        \"\"\"\n",
    "            init fm part\n",
    "        \"\"\"\n",
    "        self.fm_first_order_embeddings = nn.ModuleList(\n",
    "            [nn.Embedding(feature_size, 1) for feature_size in self.feature_sizes])\n",
    "        self.fm_second_order_embeddings = nn.ModuleList(\n",
    "            [nn.Embedding(feature_size, self.embedding_size) for feature_size in self.feature_sizes])\n",
    "        \"\"\"\n",
    "            init deep part\n",
    "        \"\"\"\n",
    "        all_dims = [self.field_size * self.embedding_size] + \\\n",
    "            self.hidden_dims + [self.num_classes]\n",
    "        for i in range(1, len(hidden_dims) + 1):\n",
    "            setattr(self, 'linear_'+str(i),\n",
    "                    nn.Linear(all_dims[i-1], all_dims[i]))\n",
    "            # nn.init.kaiming_normal_(self.fc1.weight)\n",
    "            setattr(self, 'batchNorm_' + str(i),\n",
    "                    nn.BatchNorm1d(all_dims[i]))\n",
    "            setattr(self, 'dropout_'+str(i),\n",
    "                    nn.Dropout(dropout[i-1]))\n",
    "\n",
    "    def forward(self, Xi, Xv):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - Xi: A tensor of input's index, shape of (N, field_size, 1)\n",
    "        - Xv: A tensor of input's value, shape of (N, field_size, 1)\n",
    "        \"\"\"\n",
    "        \n",
    "        fm_first_order_emb_arr = [(torch.sum(emb(Xi[:, i, :]), 1).t() * Xv[:, i]).t() for i, emb in enumerate(self.fm_first_order_embeddings)]\n",
    "        fm_first_order = torch.cat(fm_first_order_emb_arr, 1)\n",
    "        fm_second_order_emb_arr = [(torch.sum(emb(Xi[:, i, :]), 1).t() * Xv[:, i]).t() for i, emb in enumerate(self.fm_second_order_embeddings)]\n",
    "        fm_sum_second_order_emb = sum(fm_second_order_emb_arr)\n",
    "        fm_sum_second_order_emb_square = fm_sum_second_order_emb * \\\n",
    "            fm_sum_second_order_emb  # (x+y)^2\n",
    "        fm_second_order_emb_square = [\n",
    "            item*item for item in fm_second_order_emb_arr]\n",
    "        fm_second_order_emb_square_sum = sum(\n",
    "            fm_second_order_emb_square)  # x^2+y^2\n",
    "        fm_second_order = (fm_sum_second_order_emb_square -\n",
    "                           fm_second_order_emb_square_sum) * 0.5\n",
    "        \"\"\"\n",
    "            deep part\n",
    "        \"\"\"\n",
    "        deep_emb = torch.cat(fm_second_order_emb_arr, 1)\n",
    "        deep_out = deep_emb\n",
    "        for i in range(1, len(self.hidden_dims) + 1):\n",
    "            deep_out = getattr(self, 'linear_' + str(i))(deep_out)\n",
    "            deep_out = getattr(self, 'batchNorm_' + str(i))(deep_out)\n",
    "            deep_out = getattr(self, 'dropout_' + str(i))(deep_out)\n",
    "        \"\"\"\n",
    "            sum\n",
    "        \"\"\"\n",
    "        total_sum = torch.sum(fm_first_order, 1) + \\\n",
    "                    torch.sum(fm_second_order, 1) + torch.sum(deep_out, 1) + self.bias\n",
    "        return total_sum\n",
    "\n",
    "    def fit(self, loader_train, loader_val, optimizer, epochs=100, verbose=False, print_every=100):\n",
    "\n",
    "        model = self.train().to(device=self.device)\n",
    "        criterion = F.binary_cross_entropy_with_logits\n",
    "        \n",
    "        train_losses, val_losses = [], []\n",
    "\n",
    "        for ii in range(epochs):\n",
    "            \n",
    "            print('Epoch: ', ii, '\\n')\n",
    "            print('train start \\n')\n",
    "            \n",
    "            running_loss = 0\n",
    "            \n",
    "            for t, (xi, xv, y) in enumerate(loader_train):\n",
    "                xi = xi.to(device=self.device, dtype=self.dtype)\n",
    "                xv = xv.to(device=self.device, dtype=torch.float)\n",
    "                y = y.to(device=self.device, dtype=torch.float)\n",
    "                \n",
    "                total = model(xi, xv)\n",
    "                loss = criterion(total, y)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    running_loss += loss.item() * xi.shape[0]\n",
    "                \n",
    "                if verbose and t % print_every == 0:\n",
    "                    print('Iteration %d, train loss = %.4f' % (t, loss.item()))\n",
    "                    print()\n",
    "                    \n",
    "                if verbose and t % print_every*5 == 0:    \n",
    "                    train_losses += [running_loss / len(loader_train.dataset)]\n",
    "                    \n",
    "            model.eval()\n",
    "            running_loss = 0  \n",
    "                \n",
    "            with torch.no_grad():\n",
    "                print('test start \\n')\n",
    "                if ii == epochs-1:\n",
    "                    pred_fin = []\n",
    "                for t, (xi, xv, y) in enumerate(loader_val):\n",
    "                    xi = xi.to(device=self.device, dtype=self.dtype)\n",
    "                    xv = xv.to(device=self.device, dtype=torch.float)\n",
    "                    y = y.to(device=self.device, dtype=torch.float)\n",
    "\n",
    "                    total = model(xi, xv)\n",
    "                    loss = criterion(total, y)\n",
    "                    running_loss += loss.item() * xi.shape[0]\n",
    "\n",
    "                    if ii == epochs-1:\n",
    "                        pred_fin.extend(total)\n",
    "                        \n",
    "                    if verbose and t % print_every == 0:\n",
    "                        print('Iteration %d, test loss = %.4f' % (t, loss.item()))\n",
    "                        print()\n",
    "                    \n",
    "                    if verbose and t % print_every == 0:    \n",
    "                        val_losses += [running_loss / len(loader_val.dataset)]\n",
    "            \n",
    "                if ii == epochs-1:\n",
    "                    return np.array(pred_fin), train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2951745d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T17:32:26.535214Z",
     "start_time": "2024-06-15T17:32:26.530941Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8855de68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T18:10:46.727615Z",
     "start_time": "2024-06-15T18:09:51.762047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30357121, 5), (1989270, 5))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "бьем на train/test по времени (20 последних оценок идут в test)\n",
    "'''\n",
    "rating.sort_values(['user_id', 'datetime'], inplace=True)\n",
    "\n",
    "train_ratings, test_ratings = [], []\n",
    "num_test_samples = 10\n",
    "\n",
    "for userId, user_data in rating.groupby('user_id'):\n",
    "    train_ratings += [user_data[:-num_test_samples]]\n",
    "    test_ratings += [user_data[-num_test_samples:]]\n",
    "\n",
    "train_ratings = pd.concat(train_ratings)\n",
    "test_ratings = pd.concat(test_ratings)\n",
    "train_ratings.shape, test_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4a81d133",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T18:15:24.649789Z",
     "start_time": "2024-06-15T18:15:24.450015Z"
    }
   },
   "outputs": [],
   "source": [
    "test_target = test_ratings['weight'].copy()\n",
    "test_ratings.drop(['datetime', 'FLAG_05'], axis=1, inplace=True)\n",
    "train_target = train_ratings['weight'].copy()\n",
    "train_ratings.drop(['datetime', 'FLAG_05'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3afdeac9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T18:44:36.788160Z",
     "start_time": "2024-06-15T18:44:36.598307Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ratings['weight'] = np.where(train_ratings['weight']>3, 1, 0)\n",
    "test_ratings['weight'] = np.where(test_ratings['weight']>3, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b2e1a85f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T18:12:00.275129Z",
     "start_time": "2024-06-15T18:12:00.263479Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "eb31a7c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T18:44:48.990744Z",
     "start_time": "2024-06-15T18:44:48.759614Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = CriteoDataset(train_ratings, train=True)\n",
    "loader_train = DataLoader(train_data, batch_size=1028*8)\n",
    "val_data = CriteoDataset(test_ratings, train=True)\n",
    "loader_val = DataLoader(val_data, batch_size=1028*8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b205e4ab",
   "metadata": {},
   "source": [
    "# deepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "85741be5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T20:51:42.333658Z",
     "start_time": "2024-06-16T19:43:17.753565Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 6.91 µs\n",
      "Epoch:  0 \n",
      "\n",
      "train start \n",
      "\n",
      "Iteration 0, train loss = 5.7882\n",
      "\n",
      "Iteration 100, train loss = 5.5469\n",
      "\n",
      "Iteration 200, train loss = 5.3130\n",
      "\n",
      "Iteration 300, train loss = 5.1381\n",
      "\n",
      "Iteration 400, train loss = 5.5301\n",
      "\n",
      "Iteration 500, train loss = 5.6922\n",
      "\n",
      "Iteration 600, train loss = 5.1699\n",
      "\n",
      "Iteration 700, train loss = 5.3609\n",
      "\n",
      "Iteration 800, train loss = 5.5529\n",
      "\n",
      "Iteration 900, train loss = 5.1259\n",
      "\n",
      "Iteration 1000, train loss = 5.3983\n",
      "\n",
      "Iteration 1100, train loss = 5.3577\n",
      "\n",
      "Iteration 1200, train loss = 5.1770\n",
      "\n",
      "Iteration 1300, train loss = 5.1913\n",
      "\n",
      "Iteration 1400, train loss = 5.1780\n",
      "\n",
      "Iteration 1500, train loss = 5.4480\n",
      "\n",
      "Iteration 1600, train loss = 5.0968\n",
      "\n",
      "Iteration 1700, train loss = 5.3514\n",
      "\n",
      "Iteration 1800, train loss = 5.7184\n",
      "\n",
      "Iteration 1900, train loss = 5.6185\n",
      "\n",
      "Iteration 2000, train loss = 5.0941\n",
      "\n",
      "Iteration 2100, train loss = 5.3604\n",
      "\n",
      "Iteration 2200, train loss = 5.3603\n",
      "\n",
      "Iteration 2300, train loss = 5.0595\n",
      "\n",
      "Iteration 2400, train loss = 5.0736\n",
      "\n",
      "Iteration 2500, train loss = 5.3040\n",
      "\n",
      "Iteration 2600, train loss = 5.3871\n",
      "\n",
      "Iteration 2700, train loss = 5.4768\n",
      "\n",
      "Iteration 2800, train loss = 5.0453\n",
      "\n",
      "Iteration 2900, train loss = 5.2664\n",
      "\n",
      "Iteration 3000, train loss = 5.3406\n",
      "\n",
      "Iteration 3100, train loss = 5.2286\n",
      "\n",
      "Iteration 3200, train loss = 5.0062\n",
      "\n",
      "Iteration 3300, train loss = 5.0186\n",
      "\n",
      "Iteration 3400, train loss = 5.0924\n",
      "\n",
      "Iteration 3500, train loss = 5.1232\n",
      "\n",
      "Iteration 3600, train loss = 4.9677\n",
      "\n",
      "test start \n",
      "\n",
      "Iteration 0, test loss = 3.5699\n",
      "\n",
      "Iteration 100, test loss = 3.6027\n",
      "\n",
      "Iteration 200, test loss = 3.5979\n",
      "\n",
      "Epoch:  1 \n",
      "\n",
      "train start \n",
      "\n",
      "Iteration 0, train loss = 3.6234\n",
      "\n",
      "Iteration 100, train loss = 3.6171\n",
      "\n",
      "Iteration 200, train loss = 3.5190\n",
      "\n",
      "Iteration 300, train loss = 3.2267\n",
      "\n",
      "Iteration 400, train loss = 3.4849\n",
      "\n",
      "Iteration 500, train loss = 3.7107\n",
      "\n",
      "Iteration 600, train loss = 3.4919\n",
      "\n",
      "Iteration 700, train loss = 3.3905\n",
      "\n",
      "Iteration 800, train loss = 3.5914\n",
      "\n",
      "Iteration 900, train loss = 3.5068\n",
      "\n",
      "Iteration 1000, train loss = 3.5174\n",
      "\n",
      "Iteration 1100, train loss = 3.4241\n",
      "\n",
      "Iteration 1200, train loss = 3.2943\n",
      "\n",
      "Iteration 1300, train loss = 3.4125\n",
      "\n",
      "Iteration 1400, train loss = 3.2921\n",
      "\n",
      "Iteration 1500, train loss = 3.6825\n",
      "\n",
      "Iteration 1600, train loss = 3.4106\n",
      "\n",
      "Iteration 1700, train loss = 3.2829\n",
      "\n",
      "Iteration 1800, train loss = 3.7347\n",
      "\n",
      "Iteration 1900, train loss = 3.5279\n",
      "\n",
      "Iteration 2000, train loss = 3.4636\n",
      "\n",
      "Iteration 2100, train loss = 3.5784\n",
      "\n",
      "Iteration 2200, train loss = 3.4032\n",
      "\n",
      "Iteration 2300, train loss = 3.1875\n",
      "\n",
      "Iteration 2400, train loss = 3.1659\n",
      "\n",
      "Iteration 2500, train loss = 3.6893\n",
      "\n",
      "Iteration 2600, train loss = 3.5117\n",
      "\n",
      "Iteration 2700, train loss = 3.6573\n",
      "\n",
      "Iteration 2800, train loss = 3.1820\n",
      "\n",
      "Iteration 2900, train loss = 3.2649\n",
      "\n",
      "Iteration 3000, train loss = 3.5449\n",
      "\n",
      "Iteration 3100, train loss = 3.4692\n",
      "\n",
      "Iteration 3200, train loss = 3.2150\n",
      "\n",
      "Iteration 3300, train loss = 3.2126\n",
      "\n",
      "Iteration 3400, train loss = 3.3350\n",
      "\n",
      "Iteration 3500, train loss = 3.4442\n",
      "\n",
      "Iteration 3600, train loss = 3.1732\n",
      "\n",
      "test start \n",
      "\n",
      "Iteration 0, test loss = 3.2450\n",
      "\n",
      "Iteration 100, test loss = 3.2924\n",
      "\n",
      "Iteration 200, test loss = 3.2710\n",
      "\n",
      "Epoch:  2 \n",
      "\n",
      "train start \n",
      "\n",
      "Iteration 0, train loss = 3.3286\n",
      "\n",
      "Iteration 100, train loss = 3.4601\n",
      "\n",
      "Iteration 200, train loss = 3.3114\n",
      "\n",
      "Iteration 300, train loss = 3.0557\n",
      "\n",
      "Iteration 400, train loss = 3.2434\n",
      "\n",
      "Iteration 500, train loss = 3.5837\n",
      "\n",
      "Iteration 600, train loss = 3.2575\n",
      "\n",
      "Iteration 700, train loss = 3.1891\n",
      "\n",
      "Iteration 800, train loss = 3.4216\n",
      "\n",
      "Iteration 900, train loss = 3.2916\n",
      "\n",
      "Iteration 1000, train loss = 3.3538\n",
      "\n",
      "Iteration 1100, train loss = 3.1997\n",
      "\n",
      "Iteration 1200, train loss = 3.1280\n",
      "\n",
      "Iteration 1300, train loss = 3.1176\n",
      "\n",
      "Iteration 1400, train loss = 3.1391\n",
      "\n",
      "Iteration 1500, train loss = 3.5948\n",
      "\n",
      "Iteration 1600, train loss = 3.3566\n",
      "\n",
      "Iteration 1700, train loss = 3.1163\n",
      "\n",
      "Iteration 1800, train loss = 3.5379\n",
      "\n",
      "Iteration 1900, train loss = 3.3986\n",
      "\n",
      "Iteration 2000, train loss = 3.3060\n",
      "\n",
      "Iteration 2100, train loss = 3.3903\n",
      "\n",
      "Iteration 2200, train loss = 3.2233\n",
      "\n",
      "Iteration 2300, train loss = 3.0865\n",
      "\n",
      "Iteration 2400, train loss = 3.0380\n",
      "\n",
      "Iteration 2500, train loss = 3.4379\n",
      "\n",
      "Iteration 2600, train loss = 3.3245\n",
      "\n",
      "Iteration 2700, train loss = 3.5441\n",
      "\n",
      "Iteration 2800, train loss = 3.0274\n",
      "\n",
      "Iteration 2900, train loss = 3.1034\n",
      "\n",
      "Iteration 3000, train loss = 3.4051\n",
      "\n",
      "Iteration 3100, train loss = 3.3485\n",
      "\n",
      "Iteration 3200, train loss = 3.1335\n",
      "\n",
      "Iteration 3300, train loss = 3.1130\n",
      "\n",
      "Iteration 3400, train loss = 3.2568\n",
      "\n",
      "Iteration 3500, train loss = 3.3238\n",
      "\n",
      "Iteration 3600, train loss = 3.1089\n",
      "\n",
      "test start \n",
      "\n",
      "Iteration 0, test loss = 3.0950\n",
      "\n",
      "Iteration 100, test loss = 3.1456\n",
      "\n",
      "Iteration 200, test loss = 3.1197\n",
      "\n",
      "Epoch:  3 \n",
      "\n",
      "train start \n",
      "\n",
      "Iteration 0, train loss = 3.1993\n",
      "\n",
      "Iteration 100, train loss = 3.4035\n",
      "\n",
      "Iteration 200, train loss = 3.2268\n",
      "\n",
      "Iteration 300, train loss = 2.9919\n",
      "\n",
      "Iteration 400, train loss = 3.1313\n",
      "\n",
      "Iteration 500, train loss = 3.5611\n",
      "\n",
      "Iteration 600, train loss = 3.1386\n",
      "\n",
      "Iteration 700, train loss = 3.0986\n",
      "\n",
      "Iteration 800, train loss = 3.3588\n",
      "\n",
      "Iteration 900, train loss = 3.1953\n",
      "\n",
      "Iteration 1000, train loss = 3.2656\n",
      "\n",
      "Iteration 1100, train loss = 3.0778\n",
      "\n",
      "Iteration 1200, train loss = 3.0615\n",
      "\n",
      "Iteration 1300, train loss = 2.9616\n",
      "\n",
      "Iteration 1400, train loss = 3.0537\n",
      "\n",
      "Iteration 1500, train loss = 3.5950\n",
      "\n",
      "Iteration 1600, train loss = 3.3813\n",
      "\n",
      "Iteration 1700, train loss = 3.0158\n",
      "\n",
      "Iteration 1800, train loss = 3.4586\n",
      "\n",
      "Iteration 1900, train loss = 3.3409\n",
      "\n",
      "Iteration 2000, train loss = 3.2343\n",
      "\n",
      "Iteration 2100, train loss = 3.2909\n",
      "\n",
      "Iteration 2200, train loss = 3.1236\n",
      "\n",
      "Iteration 2300, train loss = 3.0421\n",
      "\n",
      "Iteration 2400, train loss = 2.9640\n",
      "\n",
      "Iteration 2500, train loss = 3.2888\n",
      "\n",
      "Iteration 2600, train loss = 3.2300\n",
      "\n",
      "Iteration 2700, train loss = 3.4935\n",
      "\n",
      "Iteration 2800, train loss = 2.9405\n",
      "\n",
      "Iteration 2900, train loss = 3.0037\n",
      "\n",
      "Iteration 3000, train loss = 3.3317\n",
      "\n",
      "Iteration 3100, train loss = 3.2830\n",
      "\n",
      "Iteration 3200, train loss = 3.1152\n",
      "\n",
      "Iteration 3300, train loss = 3.0693\n",
      "\n",
      "Iteration 3400, train loss = 3.2252\n",
      "\n",
      "Iteration 3500, train loss = 3.2596\n",
      "\n",
      "Iteration 3600, train loss = 3.0849\n",
      "\n",
      "test start \n",
      "\n",
      "Iteration 0, test loss = 3.0142\n",
      "\n",
      "Iteration 100, test loss = 3.0616\n",
      "\n",
      "Iteration 200, test loss = 3.0391\n",
      "\n",
      "Epoch:  4 \n",
      "\n",
      "train start \n",
      "\n",
      "Iteration 0, train loss = 3.1347\n",
      "\n",
      "Iteration 100, train loss = 3.3831\n",
      "\n",
      "Iteration 200, train loss = 3.1874\n",
      "\n",
      "Iteration 300, train loss = 2.9693\n",
      "\n",
      "Iteration 400, train loss = 3.0753\n",
      "\n",
      "Iteration 500, train loss = 3.5796\n",
      "\n",
      "Iteration 600, train loss = 3.0758\n",
      "\n",
      "Iteration 700, train loss = 3.0561\n",
      "\n",
      "Iteration 800, train loss = 3.3399\n",
      "\n",
      "Iteration 900, train loss = 3.1506\n",
      "\n",
      "Iteration 1000, train loss = 3.2131\n",
      "\n",
      "Iteration 1100, train loss = 3.0094\n",
      "\n",
      "Iteration 1200, train loss = 3.0394\n",
      "\n",
      "Iteration 1300, train loss = 2.8764\n",
      "\n",
      "Iteration 1400, train loss = 3.0057\n",
      "\n",
      "Iteration 1500, train loss = 3.6262\n",
      "\n",
      "Iteration 1600, train loss = 3.4290\n",
      "\n",
      "Iteration 1700, train loss = 2.9529\n",
      "\n",
      "Iteration 1800, train loss = 3.4286\n",
      "\n",
      "Iteration 1900, train loss = 3.3127\n",
      "\n",
      "Iteration 2000, train loss = 3.2040\n",
      "\n",
      "Iteration 2100, train loss = 3.2373\n",
      "\n",
      "Iteration 2200, train loss = 3.0662\n",
      "\n",
      "Iteration 2300, train loss = 3.0216\n",
      "\n",
      "Iteration 2400, train loss = 2.9172\n",
      "\n",
      "Iteration 2500, train loss = 3.1998\n",
      "\n",
      "Iteration 2600, train loss = 3.1817\n",
      "\n",
      "Iteration 2700, train loss = 3.4716\n",
      "\n",
      "Iteration 2800, train loss = 2.8907\n",
      "\n",
      "Iteration 2900, train loss = 2.9428\n",
      "\n",
      "Iteration 3000, train loss = 3.2937\n",
      "\n",
      "Iteration 3100, train loss = 3.2461\n",
      "\n",
      "Iteration 3200, train loss = 3.1255\n",
      "\n",
      "Iteration 3300, train loss = 3.0505\n",
      "\n",
      "Iteration 3400, train loss = 3.2167\n",
      "\n",
      "Iteration 3500, train loss = 3.2229\n",
      "\n",
      "Iteration 3600, train loss = 3.0782\n",
      "\n",
      "test start \n",
      "\n",
      "Iteration 0, test loss = 2.9708\n",
      "\n",
      "Iteration 100, test loss = 3.0136\n",
      "\n",
      "Iteration 200, test loss = 2.9964\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "feature_sizes = [500000, 500000]\n",
    "\n",
    "model = DeepFM(feature_sizes, embedding_size=64,\n",
    "                 hidden_dims=[64, 64], num_classes=2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-6, weight_decay=0.0)\n",
    "preds, train_losses, val_losses = model.fit(loader_train, loader_val, optimizer, epochs=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "ccecfac7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T05:27:36.933198Z",
     "start_time": "2024-06-17T05:27:36.912130Z"
    }
   },
   "outputs": [],
   "source": [
    "test_ratings['PRED'] = preds.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "e28fc423",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T05:41:17.066411Z",
     "start_time": "2024-06-17T05:41:17.051167Z"
    }
   },
   "outputs": [],
   "source": [
    "test_ratings['PD'] = F.sigmoid(torch.from_numpy(test_ratings['PRED'].values).unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "c86c3151",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T05:28:45.483486Z",
     "start_time": "2024-06-17T05:28:45.458607Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_ratings['TARGET'] = np.where(test_ratings['weight']>3, 1, 0) уже сделано"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "a70fad8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T05:28:51.124685Z",
     "start_time": "2024-06-17T05:28:51.115488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>PRED</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>4246</td>\n",
       "      <td>1</td>\n",
       "      <td>8.608948</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>8969</td>\n",
       "      <td>1</td>\n",
       "      <td>1.404488</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>4699</td>\n",
       "      <td>1</td>\n",
       "      <td>8.815282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>7162</td>\n",
       "      <td>1</td>\n",
       "      <td>11.864023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>8981</td>\n",
       "      <td>1</td>\n",
       "      <td>0.792975</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  item_id  weight       PRED  TARGET\n",
       "33        1     4246       1   8.608948       0\n",
       "53        1     8969       1   1.404488       0\n",
       "35        1     4699       1   8.815282       0\n",
       "46        1     7162       1  11.864023       0\n",
       "54        1     8981       1   0.792975       0"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "ad241f39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T05:41:26.840466Z",
     "start_time": "2024-06-17T05:41:26.333583Z"
    }
   },
   "outputs": [],
   "source": [
    "test_ratings.sort_values(['user_id', 'PD'], ascending=[True, False], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "61d1f4fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T05:41:27.425903Z",
     "start_time": "2024-06-17T05:41:27.416424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>PRED</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>PD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>2671</td>\n",
       "      <td>1</td>\n",
       "      <td>20.422924</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>15.521448</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>7162</td>\n",
       "      <td>1</td>\n",
       "      <td>11.864023</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>4699</td>\n",
       "      <td>1</td>\n",
       "      <td>8.815282</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>4246</td>\n",
       "      <td>1</td>\n",
       "      <td>8.608948</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  item_id  weight       PRED  TARGET        PD\n",
       "27        1     2671       1  20.422924       0  1.000000\n",
       "1         1      110       1  15.521448       0  1.000000\n",
       "46        1     7162       1  11.864023       0  0.999993\n",
       "35        1     4699       1   8.815282       0  0.999852\n",
       "33        1     4246       1   8.608948       0  0.999818"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "87075a04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T05:48:01.784007Z",
     "start_time": "2024-06-17T05:45:15.637712Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198927/198927 [02:46<00:00, 1197.54it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "temp_t = []\n",
    "\n",
    "for user in tqdm(test_ratings['user_id'].unique()):\n",
    "    temp_t.append(test_ratings.loc[test_ratings['user_id'] == user, 'weight'][:5].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "f86932be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T05:49:13.742164Z",
     "start_time": "2024-06-17T05:49:13.725768Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.41908840931598"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(temp_t) / len(temp_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "a45f9c63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T05:53:00.781831Z",
     "start_time": "2024-06-17T05:50:17.843370Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198927/198927 [02:42<00:00, 1221.11it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "temp_t = []\n",
    "\n",
    "for user in tqdm(test_ratings['user_id'].unique()):\n",
    "    temp_t.append(test_ratings.loc[test_ratings['user_id'] == user, 'weight'][:10].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "91463d93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T06:05:39.183546Z",
     "start_time": "2024-06-17T06:05:39.163113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.822236297737361"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(temp_t) / len(temp_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "013aac72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T06:08:34.056526Z",
     "start_time": "2024-06-17T06:05:47.838426Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198927/198927 [02:46<00:00, 1197.03it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "temp_t = []\n",
    "\n",
    "for user in tqdm(test_ratings['user_id'].unique()):\n",
    "    temp_t.append(test_ratings.loc[test_ratings['user_id'] == user, 'weight'][:3].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "50aa249b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T06:09:22.173213Z",
     "start_time": "2024-06-17T06:09:22.150664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0520743790435687"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(temp_t) / len(temp_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7d02e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "270px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
